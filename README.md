# ğŸ§± DBT + Databricks + AWS Data Pipeline

## ğŸ“– Project Overview
This project demonstrates a modern **data engineering workflow** using **dbt (Data Build Tool)** with **Databricks** as the data warehouse and **AWS S3** as the data lake.  

It transforms raw data from multiple sources â€” **orders**, **products**, **users**, and **reviews** â€” into analytics-ready gold tables for business reporting and insights.

The project follows the **Medallion Architecture** pattern (Bronze â†’ Silver â†’ Gold) to ensure data quality, scalability, and reliability.

---

## ğŸ—‚ï¸ Data Pipeline Architecture

### ğŸª£ 1. Landing Zone (AWS S3)
Raw datasets are stored in **AWS S3 buckets**, forming the ingestion layer for all data sources.

- Serves as the **data lake**  
- Holds unprocessed **raw files** (CSV)  
- Acts as the source for Databricks ingestion  

---

### ğŸ¥‰ 2. Bronze Layer (Databricks)
Data from S3 is ingested into **Databricks Delta tables** with minimal transformation.

- Basic cleaning and schema alignment  
- Ensures consistency across data sources  
- Acts as the foundation for downstream transformations  

---

### ğŸ¥ˆ 3. Silver Layer (dbt Models)
Data is cleaned, standardized, and enriched in dbt models. Relationships between **products**, **users**, **orders**, and **reviews** are defined.

Example transformations:
- Removing duplicates  
- Standardizing column names and data types  
- Joining related datasets for analytics  

---

### ğŸ¥‡ 4. Gold Layer (Analytics Models)
Aggregated models are built to power reporting and dashboards.

Key gold models:
- `gold_daily_avg_rating` â†’ Calculates daily average product ratings  
- `gold_daily_sales` â†’ Tracks daily sales and order performance  
- `product_categories` â†’ Summarizes products by category  

These models serve as the **single source of truth** for analytics and BI tools.

---

## ğŸ’¡ Why Databricks as the Data Warehouse
I chose **Databricks** because it combines scalability, performance, and simplicity for data engineering tasks.

**Key reasons:**
- âš™ï¸ **Unified platform** for data engineering, analytics, and ML  
- ğŸ’¾ **Delta Lake** provides ACID transactions and version control  
- ğŸš€ **Scalable** â€” handles large datasets and streaming data efficiently  
- ğŸ§  **Native dbt integration** â€” seamless SQL-based model execution and testing  
- ğŸ’° **Cost-effective** by leveraging AWS S3 for storage while using compute only when needed  

---

## â˜ï¸ Why AWS S3 for Data Storage
**AWS S3** was selected as the data lake for its flexibility and cost-efficiency.

**Benefits:**
- ğŸ”’ Highly available and durable storage  
- ğŸ’° Cost-effective for large data volumes  
- ğŸ”— Native integration with Databricks  
- âš¡ Supports future expansion with AWS Glue, Redshift, or Athena  

---

## ğŸ§® dbt Model Lineage

The following **lineage graph** shows the flow of data through the medallion layers â€” from raw ingestion to gold analytics models:

![dbt Lineage Graph](https://github.com/abigailmwanza/DBT_Databricks/blob/main/Images/Screenshot%202025-11-13%20at%2008.01.46.png)

**Legend:**
- ğŸŸ© **Landing:** Raw data from AWS S3  
- ğŸŸ¦ **Bronze:** Ingested and lightly cleaned data  
- ğŸ”· **Silver:** Transformed and enriched datasets  
- ğŸŸ¦ **Gold:** Aggregated business-ready insights  

---

## âš™ï¸ Tools & Technologies

| Tool | Purpose |
|------|----------|
| ğŸ§° **dbt** | Data transformation, testing, and documentation |
| ğŸ’ **Databricks** | Data warehouse and compute engine |
| â˜ï¸ **AWS S3** | Data lake for raw and intermediate data |
| ğŸ§± **Delta Lake** | Reliable storage format with ACID transactions |
| ğŸ§¾ **GitHub** | Version control and project documentation |

---

## ğŸ“Š Example Business Insights
- â­ **Average product ratings** by day and category  
- ğŸ’° **Daily sales trends** and conversion rates  
- ğŸ‘¥ **User purchase behavior** and engagement  
- ğŸ·ï¸ **Product category performance** over time  

---

## ğŸš€ Next Steps
- Automate ingestion with **Databricks Jobs**  
- Schedule dbt runs via **Databricks Workflows** or **Airflow**  
- Visualize gold models in **Power BI** or **Tableau**  
- Add **dbt tests** and **documentation** for improved data governance  

---

## ğŸ§­ Repository Structure






### Resources:
- Learn more about dbt [in the docs](https://docs.getdbt.com/docs/introduction)
- Check out [Discourse](https://discourse.getdbt.com/) for commonly asked questions and answers
- Join the [dbt community](https://getdbt.com/community) to learn from other analytics engineers
- Find [dbt events](https://events.getdbt.com) near you
- Check out [the blog](https://blog.getdbt.com/) for the latest news on dbt's development and best practices
